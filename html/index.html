<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>SLJ Test: System Latency Jitter Test</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="printing.tweeks.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="sljt-logo.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">SLJ Test
   &#160;<span id="projectnumber">1.0</span>
   </div>
   <div id="projectbrief">System Latency Jitter Test</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.1.2 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">System Latency Jitter Test </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#impatient">For the Impatient</a></li>
<li class="level1"><a href="#introduction">Introduction</a></li>
<li class="level1"><a href="#design">Design</a><ul><li class="level2"><a href="#goals">Design Goals</a></li>
<li class="level2"><a href="#constraints">Design Constraints</a></li>
</ul>
</li>
<li class="level1"><a href="#methodology">Time Measurement Methodology</a></li>
<li class="level1"><a href="#strategy">Jitter Measurement Strategy</a></li>
<li class="level1"><a href="#sources_categorization">Jitter Sources and Categorization</a><ul><li class="level2"><a href="#system_jitter">Defining System Latency Jitter</a></li>
<li class="level2"><a href="#application_jitter">Contrast with Application Jitter</a></li>
</ul>
</li>
<li class="level1"><a href="#visualization">Jitter Visualization</a><ul><li class="level2"><a href="#data_characteristics">Jitter Data Characteristics</a></li>
<li class="level2"><a href="#knee">Observing a Knee in the Data</a></li>
<li class="level2"><a href="#bin_spacing">Histogram Bin Spacing</a></li>
</ul>
</li>
<li class="level1"><a href="#output">Output Explanation</a><ul><li class="level2"><a href="#histogram_display">Histogram Display</a></li>
<li class="level2"><a href="#statistics">Statistics</a></li>
<li class="level2"><a href="#recommendations">Recommended Test Parameters</a></li>
</ul>
</li>
<li class="level1"><a href="#logging">Logging and Plotting Outliers</a></li>
<li class="level1"><a href="#options">Command Line Options</a></li>
<li class="level1"><a href="#examples">Example Output</a><ul><li class="level2"><a href="#low_jitter">Low-Jitter Server</a></li>
<li class="level2"><a href="#busy_server">Busy Server</a></li>
</ul>
</li>
<li class="level1"><a href="#availability">Availability</a></li>
<li class="level1"><a href="#related">Related Work</a></li>
<li class="level1"><a href="#acknowledgements">Acknowledgements</a></li>
<li class="level1"><a href="#license">License</a></li>
<li class="level1"><a href="#disclaimers">Disclaimers</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="impatient"></a>
For the Impatient</h1>
<ul>
<li>Run a pre-compiled binary:<code> bin/&lt;Platform&gt;/sljtest</code> </li>
<li>On Windows, open a <code>cmd</code> window and run <code>sljtext.exe</code> in that. </li>
<li>Or build from source and run:<code> cd src; make; ./sljtest</code> </li>
<li>The output should be pretty self explanatory. </li>
<li>Put your right ear on your shoulder to see the histogram. </li>
<li>See <a class="el" href="index.html#output">Output Explanation</a> below for details. </li>
<li>See <a class="el" href="index.html#options">Command Line Options</a> below for fine tuning and features. </li>
<li>See <a class="el" href="index.html#examples">Example Output</a> below for example output and analysis. </li>
<li>Browse code by <a href="globals.html"><b>functions, variables, defines, enums, and typedefs</b></a>.</li>
</ul>
<h1><a class="anchor" id="introduction"></a>
Introduction</h1>
<p>Ultra Messaging customers use our software to build complicated systems that often process millions of messages per second. Common goals are low latency and high throughput, but many customers also value freedom from latency jitter. A system with no latency jitter would show exactly the same latency for every message passing through it. Consistency is the hallmark of low-jitter systems.</p>
<p>It's hard to be consistent in doing repetitive work when you're being interrupted all the time. For humans, consistency in performing a repeated task requires freedom from interruptions.</p>
<p>Roughly the same idea applies to computer systems. SLJ Test measures the ability of a system to provide a CPU core that is able to consistently execute a repetitive task. The emphasis is <em>not</em> on the average time taken to do a task but rather on the <em>variance</em> in time between repetitions of the task.</p>
<p>We will define system latency jitter more thoroughly <a class="el" href="index.html#sources_categorization">below</a>, but for now we can think of it as the jitter measured by an application that introduces no jitter of its own. System latency jitter will be present in any application run by the system. It represents the lower bound for jitter that might be expected of any application running on the system.</p>
<p>SLJ Test measures system latency jitter and provides a simple but effective visualization of it for analysis.</p>
<p>Running a system latency jitter benchmark under different conditions can provide insight into the causes of system latency jitter. Here are some test ideas:</p>
<ul>
<li>Compare results with other CPU cores idle and with them working </li>
<li>Compare the same OS running on different server hardware </li>
<li>Compare different OSes running on the same server hardware </li>
<li>Compare an OS running native to an OS running on a Hypervisor </li>
<li>Compare BIOS settings for their jitter impact </li>
<li>Compare single-user mode to multi-user mode </li>
<li>Compare short test runs to long test runs </li>
<li>Compare a sleeping thread to a hot thread burning CPU time </li>
<li>Compare various CPU cores to each other </li>
<li>Compare hyperthreaded shared cores to unshared cores </li>
<li>Compare benefits of cset, taskset, etc.</li>
</ul>
<h1><a class="anchor" id="design"></a>
Design</h1>
<p>The design of SLJ Test was motivated by goals, but bounded by constraints.</p>
<h2><a class="anchor" id="goals"></a>
Design Goals</h2>
<p>Two key design goals drove the development of SLJ Test:</p>
<ul>
<li>Make measurements to quantify system latency jitter. These measurements can be used as benchmarks for performance comparisons between systems or to guide tuning efforts. </li>
<li>Provide a visualization of collected data that aids in analysis and characterization of system latency jitter. The visualization can help drive jitter tuning efforts.</li>
</ul>
<h2><a class="anchor" id="constraints"></a>
Design Constraints</h2>
<p>The above goals had to be met within several design constraints.</p>
<ul>
<li><em>Test Speed</em> Often in our experience, reducing jitter is a process of test, hunch, tune, and retest. It is sometimes possible to quickly find and remove a source of jitter, but more often, repeated tuning and testing are required. Hence SLJ Test was designed to produce quick results so that the effect of tuning changes could be tested quickly.</li>
</ul>
<ul>
<li><em>Simplicity</em> Benchmarking and tuning opportunities are often fleeting, so it's important to get accurate results and actionable information simply. SLJ Test combines data collection, analysis, and visualization in a single tool that is easy to operate.</li>
</ul>
<ul>
<li><em>Portability</em> It is useful to be able to compare results across a variety of operating systems. SLJ Test is a small code base that uses few system libraries for good portability. It requires an x86 processor for access to the RDTSC instruction. It comes with pre-compiled binaries for Linux, Solaris, Mac OS, FreeBSD, and Windows.</li>
</ul>
<ul>
<li><em>Information Density</em> Even a 1-second test run produces tens of millions of data points. Visualization of these data points can be key to forming strategies for jitter reduction. The range of data values can easily span 6 orders of magnitude, so they can be difficult to represent on even a high-resolution display. The constraints of simplicity and portability are best met with a character interface rather than a graphical one. So SLJ Test aims to analyze and visualize all the data using easily portable character graphics.</li>
</ul>
<h1><a class="anchor" id="methodology"></a>
Time Measurement Methodology</h1>
<p>The CPU's <a href="http://en.wikipedia.org/wiki/Time_Stamp_Counter">Time Stamp Counter</a> (TSC) is useful for measuring how long tasks take, especially when very short times are involved. It's usually counting at a rate of 3 or 4 billion counts per second. That gives it a resolution of 333 to 250 picoseconds.</p>
<p>Elapsed ticks can be measured by reading the TSC before and after doing a task, then subtracting the timestamps. This gives the number of ticks taken by the task, plus the time taken to read the TSC once.</p>
<div class="fragment"><div class="line">uint64_t start, stop, elapsed_ticks;</div>
<div class="line"></div>
<div class="line"><a class="code" href="sljtest_8c.html#a8af02d9cb05d7262a77689bf809384f7" title="Read value of TSC into a uint64_t.">rdtsc</a>(start);</div>
<div class="line"><span class="comment">// Do some task</span></div>
<div class="line"><a class="code" href="sljtest_8c.html#a8af02d9cb05d7262a77689bf809384f7" title="Read value of TSC into a uint64_t.">rdtsc</a>(stop);</div>
<div class="line">elapsed_ticks = stop - start;</div>
</div><!-- fragment --><p>When elapsed ticks for an interval are known, the elapsed time in seconds can be computed by dividing elapsed ticks by the CPU frequency in Hertz.</p>
<p>When elapsed time for an interval is known, CPU frequency in Hertz can be computed by dividing the elapsed ticks by the elapsed time.</p>
<p>If a task is repeated many times while measuring elapsed ticks, there will undoubtedly be some variation (jitter) in the number of ticks taken to do the task, even though the work should be the same each time for tasks with no conditional logic.</p>
<h1><a class="anchor" id="strategy"></a>
Jitter Measurement Strategy</h1>
<p>Jitter is most apparent when we measure the elapsed time taken to do quick tasks. The limiting case is to measure the time needed to just read the TSC. Measuring the delta between two adjacent readings of the TSC does this. It is equivalent to measuring the elapsed time taken by a null task, plus the time to read the TSC.</p>
<p>We want to avoid conditional logic since it may cause jitter by varying CPU cache hit rates. We want to quickly take as many timestamp pairs as possible to maximize jitter detection opportunities. Both these goals are met by using manual <a href="http://en.wikipedia.org/wiki/Loop_unwinding">loop unwinding</a> to collect the timestamps. Analysis work on the collected timestamps is never done while collecting, but only after completion of the unwound loop.</p>
<div class="fragment"><div class="line">uint64_t deltas[10], *dp;</div>
<div class="line"></div>
<div class="line"><span class="keywordflow">do</span> {</div>
<div class="line">        dp = deltas;</div>
<div class="line"></div>
<div class="line">        <span class="keyword">register</span> uint64_t t0, t1, t2, t3, t4, t5, t6, t7, t8, t9, t10;</div>
<div class="line"></div>
<div class="line">        <span class="comment">// Take a block of 11 timestamps and compute their differences into</span></div>
<div class="line">        <span class="comment">// a 10-element array.</span></div>
<div class="line">        <span class="comment">//</span></div>
<div class="line">        <span class="comment">// Do an &quot;unwound loop&quot; so there&#39;s no branching or other work</span></div>
<div class="line"></div>
<div class="line">        <a class="code" href="sljtest_8c.html#a8af02d9cb05d7262a77689bf809384f7" title="Read value of TSC into a uint64_t.">rdtsc</a>(t0);</div>
<div class="line">        <a class="code" href="sljtest_8c.html#a8af02d9cb05d7262a77689bf809384f7" title="Read value of TSC into a uint64_t.">rdtsc</a>(t1);</div>
<div class="line">        <a class="code" href="sljtest_8c.html#a8af02d9cb05d7262a77689bf809384f7" title="Read value of TSC into a uint64_t.">rdtsc</a>(t2);</div>
<div class="line">        . . .</div>
<div class="line">        <a class="code" href="sljtest_8c.html#a8af02d9cb05d7262a77689bf809384f7" title="Read value of TSC into a uint64_t.">rdtsc</a>(t9);</div>
<div class="line">        <a class="code" href="sljtest_8c.html#a8af02d9cb05d7262a77689bf809384f7" title="Read value of TSC into a uint64_t.">rdtsc</a>(t10);</div>
<div class="line"></div>
<div class="line">        *dp++ = t1 - t0;</div>
<div class="line">        *dp++ = t2 - t1;</div>
<div class="line">        . . .</div>
<div class="line">        *dp++ = t10 - t9;</div>
<div class="line"></div>
<div class="line">        <span class="comment">// Now that we&#39;re out of the timing loop, we can take all the</span></div>
<div class="line">        <span class="comment">// CPU time that we need for analysis.</span></div>
<div class="line"></div>
<div class="line">        <span class="keywordflow">for</span> (dp=deltas; dp&lt;deltas+<a class="code" href="sljtest_8c.html#a25f003de16c08a4888b69f619d70f427">ARRAY_SIZE</a>(deltas); dp++) {</div>
<div class="line">                <span class="comment">// Analysis as needed</span></div>
<div class="line">        }</div>
<div class="line">} <span class="keywordflow">while</span> (collecting);</div>
</div><!-- fragment --><h1><a class="anchor" id="sources_categorization"></a>
Jitter Sources and Categorization</h1>
<p>It's true that each repeated test would run at the minimum elapsed time if there were no jitter. Any test repetition that takes longer than the minimum was delayed by waiting for some system resource. It had to wait because there was contention for a resource that was already in use elsewhere and could not be shared. Examples of shared resources might be data paths on the CPU chip, hyperthreaded execution units, shared caches, memory busses, CPU cores, kernel data structures and critical sections. So it's correct but simplistic to say that all jitter comes from contention.</p>
<p>We can make better progress at reducing jitter if we identify discrete sources of jitter and categorize them for discussion and measurement.</p>
<p>The CPU scheduler in the OS can be a source of jitter if a thread is moved between CPU cores since cache misses in the new core will initially slow execution compared to the old core. Virtual machine hypervisors may prevent a thread from holding the attention of a CPU core indefinitely. Even things at the CPU hardware level like shared cache contention and hyperthreading can add jitter.</p>
<p>Jitter in elapsed time measurements for doing identical tasks is also a measure of things distracting a CPU core from running a thread. Some runs of a task may take longer than others because a CPU core is not able to finish the task without first doing additional work. Hardware interrupts are one possible source of such additional work, but it's best to think of interruptions more broadly. Anything that keeps a CPU core from executing at full speed is a distraction that hurts performance and adds jitter.</p>
<p>Since jitter sources exist at many layers of a system, we can envision a stack of jitter sources by layer as shown below:</p>
<div class="image">
<img src="jitter_layers.png" alt="jitter_layers.png"/>
<div class="caption">
Figure 1: Jitter by layers and sources, showing sums.</div></div>
<p> Note that jitter measurements from lower layers propagate to higher layers.</p>
<h2><a class="anchor" id="system_jitter"></a>
Defining System Latency Jitter</h2>
<p>This code aims to measure system latency jitter so that a system can be tuned to minimize it. Reducing jitter in elapsed time measurements made with the TSC minimizes jitter throughout the system. Reading the TSC value is a very low-level operation. It is independent of higher-level languages and libraries like Ultra Messaging.</p>
<p>We define system latency jitter as the jitter measured at the lowest-possible level at which messaging or application software can be written. Applications are the likely source of any jitter measured in excess of the system latency jitter.</p>
<p>SLJ Test uses no network I/O, no messaging library, no memory-managed language, or abstraction layers. It's measuring jitter as close to the machine hardware as we know how to get with C and in-line assembler. Said differently, jitter measured by SLJ Test is coming from server hardware, BIOS, CPU, VM, and OS sources.</p>
<h2><a class="anchor" id="application_jitter"></a>
Contrast with Application Jitter</h2>
<p>Applications doing repetitive tasks may introduce their own jitter by slightly varying the task. Conditional execution in the form of branches and loops is an obvious source of jitter because of cache misses and other effects. Even when code paths appear to be free from branches and loops, jitter can be caused by library calls like <code>malloc()</code> and <code>free()</code> that necessarily contain their own conditional code paths. We categorize all such jitter as application jitter.</p>
<p>Adding networking, messaging libraries, memory-managed language wrappers, and/or abstraction layers will only magnify the effects of system latency jitter. One microsecond of jitter on each step of a 1000-step task can turn into one millisecond of jitter for the whole task.</p>
<p>Note that we use the term "jitter" here in the general sense meaning variation from an expected norm. The system latency jitter discussed here is just one component of the latency variation observed in application-level tests like repeated message round-trip time tests. The standard deviation of latency measured in message round-trip times is often loosely called "jitter," but we are making a distinction here between that and system latency jitter. System latency jitter is that component that can never be removed from an application jitter measurement because it is present in all applications running on the system.</p>
<h1><a class="anchor" id="visualization"></a>
Jitter Visualization</h1>
<p>Even a short system latency jitter test produces many millions of data points, so a concise visualization of the data is required to quickly interpret the results. Specifically, a good visualization of the data would allow quick and meaningful comparisons with other test runs.</p>
<p>A <a href="http://en.wikipedia.org/wiki/Histogram">histogram</a> is the natural choice for visualizing system latency jitter test data. Histograms are commonly used in applications like displaying the variance in adult height among a population. However, inherent differences in system latency jitter data and display constraints suggest we make some changes from common histograms. Specifically, we use non-uniform bin spacing, logarithmic value display, and rotated axes. Details are presented in following sections.</p>
<h2><a class="anchor" id="data_characteristics"></a>
Jitter Data Characteristics</h2>
<p>Although many natural processes follow a normal distribution, the elapsed times measured in system latency jitter tests are not expected to follow a normal distribution. One reason is that there is a hard lower bound on the time required to read the TSC so we shouldn't expect a symmetric or uniform distribution around the mean. Indeed in most cases, the mean and at least one mode are quite close to the lower bound with a very long tail of outliers. Another reason is that the different processes that introduce jitter often produce multimodal distributions.</p>
<p>We often see two or more closely-spaced modes near the lower bound and then several more widely-spaced modes that are perhaps orders of magnitude greater. Conventional linear histogram bin spacing would not visualize this data well. Small numbers of bins would combine nearby modes that have distinct causes. Large numbers of bins leave many bins empty and make it difficult to see patterns.</p>
<p>A high-resolution display might be able to distinctly show both closely- and widely-spaced modes with consistent scaling, but it's hard to write portable code for high-resolution displays.</p>
<h2><a class="anchor" id="knee"></a>
Observing a Knee in the Data</h2>
<p>A graph of the cumulative percentage of all samples always rises from 0 to 100% as we move across the histogram bins. With system latency jitter data, we often see the cumulative percentage rise quickly from 0 to &gt;90% in just a few bins, but then rise much more slowly after that. Thus a graph of the cumulative percentage often shows a <em>knee</em> range where the growth per bin slows.</p>
<h2><a class="anchor" id="bin_spacing"></a>
Histogram Bin Spacing</h2>
<p>We make it easier for modes to be seen by using two different bin spacings in the same histogram. The number of bins in the histogram is divided into two halves. The lower half of the bins are lineraly spaced while the upper half are exponentially spaced. This provides detail near the lower bound where modes are closely spaced, while preserving the range needed to show modes that occur 5 or more orders of magnitude above the mean. For linguistic convenience, the bins in the lower half of the histogram are said to be "below
the knee," while those in the upper half are above.</p>
<p>The hard lower bound mentioned above means that bins near 0 will likely be empty. We define a minimum expected value that improves the resolution below the knee. Any values below the expected minimum are accumulated in the first bin.</p>
<p>Command line options allow setting the number of bins, the knee value, and a minimum value which is the lower bound of the first bin. Here is an example for 20 histogram bins with a minimum value of 10% of the knee value:</p>
<pre class="fragment"> Bin            Range
 0              min +  0- 10% * (knee-min)
 1              min + 10- 20% * (knee-min)
 2              min + 20- 30% * (knee-min)
 3              min + 30- 40% * (knee-min)
 4              min + 40- 50% * (knee-min)
 5              min + 50- 60% * (knee-min)
 6              min + 60- 70% * (knee-min)
 7              min + 70- 80% * (knee-min)
 8              min + 80- 90% * (knee-min)
 9              min + 90-100% * (knee-min)
 -              --------------------------
 10                       1-2 * knee
 11                      2-10 * knee
 12                     10-20 * knee
 13                    20-100 * knee
 14                   100-200 * knee
 15                  200-1000 * knee
 16                 1000-2000 * knee
 17                2000-10000 * knee
 18               10000-20000 * knee
 19              20000-100000 * knee
</pre><h1><a class="anchor" id="output"></a>
Output Explanation</h1>
<p>Default values produce output that is 28 lines by no more than 80 characters. This small space contains areas with many statistics and a compact visualization of system latency jitter.</p>
<p>The following figure gives a quick overview of the 5 output areas while following sections give detail on each.</p>
<div class="image">
<img src="output_explanation.png" alt="output_explanation.png"/>
<div class="caption">
Figure 2: Output Explanation.</div></div>
 <h2><a class="anchor" id="histogram_display"></a>
Histogram Display</h2>
<p>The histogram is displayed rotated 90 degrees clockwise from a conventional display to keep the code portable across operating systems and avoid the requirement for a high-resolution graphical display. The histogram bins are separated by elapsed time and are displayed vertically one bin per line instead of the more conventional horizontal display. The count of the samples in each bin are displayed horizontally instead of the more conventional vertical display.</p>
<p>Note that the number of counts per bin is displayed on a logarithmic scale so that it will fit on low-resolution screens. The magnitude (width) of all bins is scaled so that the bin with the largest count uses the full line width (default 80).</p>
<p>The first half of the bins below the knee setting are linearly spaced in the hope of catching the mode, the average, and the vast majority of the samples. The second half of the bins are spaced roughly by half orders of magnitude so that every pair of bins represents one order of magnitude.</p>
<p>So the top-half (left-half) of the histogram is a <a href="http://en.wikipedia.org/wiki/Semi-log">semi-log plot</a> while the bottom-half (right-half) is a <a href="http://en.wikipedia.org/wiki/Log-log_plot">log-log plot</a>.</p>
<h2><a class="anchor" id="statistics"></a>
Statistics</h2>
<p>Each line of output contains statistics for the associated histogram bin and a visualization of the data. Column values are given in the table below.</p>
<table class="doxtable">
<tr>
<th align="left">Column </th><th align="left">Contents</th></tr>
<tr>
<td align="left">Time </td><td align="left">The upper bound of this bin in terms of elapsed time between adjacent reads of the TSC. </td></tr>
<tr>
<td align="left">Ticks </td><td align="left">The same as above, but in ticks of the TSC. </td></tr>
<tr>
<td align="left">Count </td><td align="left">A count of the number of deltas falling into this bin (only seen without <code>-s</code> flag). </td></tr>
<tr>
<td align="left">Sum </td><td align="left">The sum of deltas falling into this bin (only seen with <code>-s</code> flag). </td></tr>
<tr>
<td align="left">Percent </td><td align="left">The percentage of all samples in this bin. </td></tr>
<tr>
<td align="left">Cumulative </td><td align="left">The cumulative percentage of all samples in this bin and lower. </td></tr>
<tr>
<td align="left">Graph </td><td align="left">A graph of the Count column. </td></tr>
</table>
<p>If you want to see more detail in the histogram and have a window with many rows, try increasing the number of bins. Or try increasing the output line width if you have a window with more than 80 columns.</p>
<p>By default, the per-bin statistics and histogram <em>count</em> the deltas that fall into each histogram bin. This weights large and small deltas equally, which can be undesirable if trying to measure the total system latency jitter. The <code>-s</code> flag can be added to the command line to instead report the <em>sum</em> of the deltas that fall into each histogram bin.</p>
<p>After per-bin statistics and histogram lines, there is a section of statistics for the overall test run. While the histogram is useful for characterizing a system's latency jitter and tuning, the overall statistics may be more useful for making benchmark comparisons between systems. In particular, the maximum and standard deviation in units of time are probably the two most important numbers for most Ultra Messaging customers.</p>
<h2><a class="anchor" id="recommendations"></a>
Recommended Test Parameters</h2>
<p>Design goals and constraints drove the decision to combine data collection and visualization into a single step. This creates a bit of a chicken-and-egg problem because minimum and knee values must be set before data collection yet the optimal values cannot be known until after data collection and often visualization. The default minimum and knee values may be good enough for a quick analysis, but tuning these values away from the defaults often provides sharper insight.</p>
<p>There are heuristics built into SLJ Test that check the minimum and knee values for reasonability after data collection. You'll see this recommendation if the minimum data sample is less that 80% of the configured expected minimum.</p>
<pre class="fragment">Recommend min setting of x ticks
</pre><p>Where <em>x</em> is 80% of the minimum data sample seen.</p>
<p>Similarly you'll see this recommendation if the cumulative sample count at the middle histogram bin is less than 90% the total samples.</p>
<pre class="fragment">Recommend increasing knee setting from x ticks
</pre><p>Where <em>x</em> is the configured knee value.</p>
<p>Finally you'll see this recommendation if the cumulative sample count at the middle histogram bin is greater than 99% of the total samples.</p>
<pre class="fragment">Recommend decreasing knee setting from x ticks
</pre><p>Where <em>x</em> is the configured knee value.</p>
<h1><a class="anchor" id="logging"></a>
Logging and Plotting Outliers</h1>
<p>An outlier is defined as any TSC delta greater than the knee. The <code>-f</code> option names a file where outliers will be written. The format is <em>x</em>, <em>y</em> where <em>x</em> is the time of the outlier in ms relative to the start of the test and <em>y</em> is the size of the outlier in us. Note the different units between axes.</p>
<p>The expectation is that you'll give this data to the graphing software of your choice and request an <em>x</em> <em>y</em> scatter plot. Visual analysis of the plot may help you spot any periodic patterns in the jitter. The period may give you clues to the source of the jitter.</p>
<div class="image">
<img src="NoTimeCorrelation.png" alt="NoTimeCorrelation.png"/>
<div class="caption">
Figure 3: Outliers with no apparent time correlation.</div></div>
<p> Better yet, do an FFT on the data to move it from the time domain to the frequency domain.</p>
<p>Note that <em>x</em> may not be near zero if the outlier buffer wraps around. If you're worried about the outlier buffer wrapping around, my advice is to increase the knee to classify fewer deltas as outliers rather than making the buffer bigger. The default size is probably big enough for you to spot any periodic patterns.</p>
<h1><a class="anchor" id="options"></a>
Command Line Options</h1>
<pre class="fragment"> -b bins        Set the number of Bins in the histogram (20)
 -f outfile     Name of file for outlier data to be written (no file written)
 -h             Print Help
 -k knee        Set the histogram Knee value in TSC ticks (50)
 -m min         Set the Minimum expected value in TSC ticks (10)
 -o outbuf      Size of outlier buffer in outliers (10000)
 -p pause       Pause msecs just before starting jitter test loop (0)
 -r runtime     Run jitter testing loops until seconds pass (1)
 -s             Sum deltas falling into each bin (instead of just counting deltas falling into bin)
 -w width       Output line Width in characters (80)
</pre><h1><a class="anchor" id="examples"></a>
Example Output</h1>
<p>Following sections show data collected on various systems under various conditions with comments.</p>
<h2><a class="anchor" id="low_jitter"></a>
Low-Jitter Server</h2>
<p>This output came from a server in our lab that had been tuned for low jitter.</p>
<pre class="fragment">Time    Ticks    Count        Percent    Cumulative  Graph ln(Count-e)
10.7ns  32       0             0.0000%    0.0000%    
11.4ns  34       0             0.0000%    0.0000%    
  12ns  36       6997631      42.0733%   42.0733%    *************************
12.7ns  38       0             0.0000%   42.0733%    
13.4ns  40       0             0.0000%   42.0733%    
  14ns  42       0             0.0000%   42.0733%    
14.7ns  44       0             0.0000%   42.0733%    
15.4ns  46       9634329      57.9265%   99.9998%    **************************
  16ns  48       0             0.0000%   99.9998%    
16.7ns  50       0             0.0000%   99.9998%    

33.4ns  100      0             0.0000%   99.9998%    
 167ns  500      0             0.0000%   99.9998%    
 334ns  1000     2             0.0000%   99.9998%    *
1.67us  5000     36            0.0002%  100.0000%    *****
3.34us  10000    2             0.0000%  100.0000%    *
16.7us  50000    0             0.0000%  100.0000%    
33.4us  100000   0             0.0000%  100.0000%    
 167us  500000   0             0.0000%  100.0000%    
 334us  1000000  0             0.0000%  100.0000%    
Infini  Infinite 0             0.0000%  100.0000%    

Timing was measured for  229ms, 22.91% of runtime
CPU speed measured  : 2992.58 MHz over 16632000 iterations
Min / Average / Std Dev / Max :   36   /   41   /    6   / 6984 ticks
Min / Average / Std Dev / Max :   12ns / 13.7ns / 1.67ns / 2.33us
</pre><p>42% of the samples were in the 12 ns bin and almost 58% were in the 15.4 ns bin. Together, 99.9998% of all samples were in these two bins. There were zero samples in the 4 bins between these two, producing a nice bi-modal histogram. The outlier samples were just 36 out of 16.6 million.</p>
<h2><a class="anchor" id="busy_server"></a>
Busy Server</h2>
<p>This output came from a busy server in our lab.</p>
<pre class="fragment">Time    Ticks    Count        Percent    Cumulative  Graph ln(Count-e)
6.92ns  23       18332137     67.6263%   67.6263%    **************************
7.82ns  26       788340        2.9081%   70.5344%    *********************
8.72ns  29       2679472       9.8844%   80.4189%    ***********************
9.62ns  32       414           0.0015%   80.4204%    *********
10.5ns  35       63212         0.2332%   80.6536%    *****************
11.4ns  38       4972436      18.3431%   98.9966%    ***********************
12.3ns  41       90            0.0003%   98.9970%    ******
13.2ns  44       54281         0.2002%   99.1972%    ****************
14.1ns  47       216764        0.7996%   99.9968%    *******************
  15ns  50       306           0.0011%   99.9980%    ********

30.1ns  100      4             0.0000%   99.9980%    *
 150ns  500      3             0.0000%   99.9980%    *
 301ns  1000     0             0.0000%   99.9980%    
 1.5us  5000     173           0.0006%   99.9986%    *******
3.01us  10000    315           0.0012%   99.9998%    ********
  15us  50000    52            0.0002%  100.0000%    ******
30.1us  100000   1             0.0000%  100.0000%    *
 150us  500000   0             0.0000%  100.0000%    
 301us  1000000  0             0.0000%  100.0000%    
Infini  Infinite 0             0.0000%  100.0000%    

Timing was measured for  188ms, 18.85% of runtime
CPU speed measured  : 3324.96 MHz over 27108000 iterations
Min / Average / Std Dev / Max :   18   /   23   /   42   / 88982 ticks
Min / Average / Std Dev / Max : 5.41ns / 6.92ns / 12.6ns / 26.8us
</pre><p>It shows a much faster average time than the <a class="el" href="index.html#low_jitter">low-jitter server</a> above, but the standard deviation is over 7 times larger while the maximum is over 11 times larger.</p>
<h1><a class="anchor" id="availability"></a>
Availability</h1>
<p>Informatica makes the binary and <a href="https://github.com/bobvan/SLJtest">source code for SLJ Test</a> freely available so that our customers can use it to work with their hardware and software vendors to reduce jitter. We pioneered this idea with our <a href="https://community.informatica.com/solutions/informatica_mtools">mtools</a> software for testing multicast UDP performance. Many customers have used mtools to work with their NIC, driver, OS, and server vendors to improve UDP multicast performance. We hope that this code can be used between our customers and their other vendors to reduce system latency jitter.</p>
<h1><a class="anchor" id="related"></a>
Related Work</h1>
<p>Gil Tene of Azul Systems has written <a href="http://www.azulsystems.com/jHiccup">jHiccup</a>, a tool for measuring latency jitter in Java JVM runtime systems.</p>
<dl class="section copyright"><dt>Copyright</dt><dd>(c) Copyright 2011, 2012 Informatica Corp.</dd></dl>
<dl class="section author"><dt>Author</dt><dd>Robert A. Van Valzah</dd></dl>
<h1><a class="anchor" id="acknowledgements"></a>
Acknowledgements</h1>
<p>Inspired by David Riddoch of Solarflare</p>
<p>Idea for <code>-s</code> flag to sum deltas into histogram bins instead of just counting them from Erez Strauss</p>
<h1><a class="anchor" id="license"></a>
License</h1>
<p>Redistribution and use in source and binary forms, with or without modification, are permitted without restriction. The author will be disappointed if you use this software for making war, mulching babies, or improving systems running competing messaging software.</p>
<h1><a class="anchor" id="disclaimers"></a>
Disclaimers</h1>
<p>THE SOFTWARE IS PROVIDED "AS IS" AND INFORMATICA DISCLAIMS ALL WARRANTIES EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION, ANY IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. INFORMATICA DOES NOT WARRANT THAT USE OF THE SOFTWARE WILL BE UNINTERRUPTED OR ERROR-FREE. INFORMATICA SHALL NOT, UNDER ANY CIRCUMSTANCES, BE LIABLE TO LICENSEE FOR LOST PROFITS, CONSEQUENTIAL, INCIDENTAL, SPECIAL OR INDIRECT DAMAGES ARISING OUT OF OR RELATED TO THIS AGREEMENT OR THE TRANSACTIONS CONTEMPLATED HEREUNDER, EVEN IF INFORMATICA HAS BEEN APPRISED OF THE LIKELIHOOD OF SUCH DAMAGES. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Dec 27 2012 21:19:20 for SLJ Test by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.1.2
</small></address>
</body>
</html>
